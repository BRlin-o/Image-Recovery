{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11696729616733092314\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10001629184\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9697310516098997043\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n",
      "Fri Nov 26 23:59:57 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 472.47       Driver Version: 472.47       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 42%   35C    P8     5W / 250W |    712MiB / 11264MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1656    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      1676    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      5188    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5412    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5820    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      7844    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      8364    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9884    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10432    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     10584    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     11244    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     12816    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     13928      C   ...f_1.14-jupyter\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "## 設定GPU 可使用 nvidia-smi 查看GPU編號\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Training\n",
    "Having implemented and tested all the components of the final networks in steps 1-3, we are now ready to train the network on a large dataset (ImageNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from libs.pconv_model_bak import PConvUnet\n",
    "from libs.util import random_mask\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.ioff()\n",
    "\n",
    "# SETTINGS\n",
    "TRAIN_DIR = r\"D:\\Documents\\Kaggle\\Kaggle-imagenet\\input\\DET\\train\\ILSVRC2013_train\\\\\"\n",
    "TEST_DIR = r\"D:\\Documents\\Kaggle\\Kaggle-imagenet\\input\\DET\\pexels\\\\\"\n",
    "VAL_DIR = r\"D:\\Documents\\Kaggle\\Kaggle-imagenet\\input\\DET\\val\\val_100\\\\\"\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train & test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_13928/721583525.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\gpu\\AppData\\Local\\Temp/ipykernel_13928/721583525.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    ori = next(generator)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class DataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, class_mode=None, *args, **kwargs)\n",
    "        while True:w\n",
    "            \n",
    "            # Get augmentend image samples\n",
    "            ori = next(generator)\n",
    "\n",
    "            # Get masks for each image sample\n",
    "            mask = np.stack([random_mask(ori.shape[1], ori.shape[2]) for _ in range(ori.shape[0])], axis=0)\n",
    "\n",
    "            # Apply masks to all image sample\n",
    "            masked = deepcopy(ori)\n",
    "            masked[mask==0] = 1\n",
    "\n",
    "            # Yield ([ori, masl],  ori) training batches\n",
    "            # print(masked.shape, ori.shape)\n",
    "            gc.collect()\n",
    "            yield [masked, mask], ori\n",
    "            \n",
    "# Create training generator\n",
    "train_datagen = DataGenerator(  \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR, target_size=(512, 512), batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "val_datagen = DataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR, target_size=(512, 512), batch_size=BATCH_SIZE, seed=1\n",
    ")\n",
    "\n",
    "# Create testing generator\n",
    "test_datagen = DataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR, target_size=(512, 512), batch_size=BATCH_SIZE, seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 21] 裝置未就緒。: 'D:\\\\Documents\\\\Kaggle\\\\Kaggle-imagenet\\\\input\\\\DET\\\\pexels\\\\\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13928/254692749.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Pick out an example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmasked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mori\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Show side by side\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13928/3243651827.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, *args, **kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_1.14-jupyter\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m         )\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_1.14-jupyter\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 21] 裝置未就緒。: 'D:\\\\Documents\\\\Kaggle\\\\Kaggle-imagenet\\\\input\\\\DET\\\\pexels\\\\\\\\'"
     ]
    }
   ],
   "source": [
    "# Pick out an example\n",
    "test_data = next(test_generator)\n",
    "(masked, mask), ori = test_data\n",
    "\n",
    "# Show side by side\n",
    "for i in range(len(ori)):\n",
    "    _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axes[0].imshow(masked[i,:,:,:])\n",
    "    axes[1].imshow(mask[i,:,:,:] * 1.)\n",
    "    axes[2].imshow(ori[i,:,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_callback(model):\n",
    "    \"\"\"Called at the end of each epoch, displaying our previous test images,\n",
    "    as well as their masked predictions and saving them to disk\"\"\"\n",
    "    \n",
    "    # Get samples & Display them        \n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[2].imshow(ori[i,:,:,:])\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[2].set_title('Original Image')\n",
    "                \n",
    "        plt.savefig(r'data/test_samples/img_{}_{}.png'.format(i, pred_time))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 - with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = PConvUnet(weight_filepath='data/logs/')\n",
    "model.load(r\"C:\\Users\\MAFG\\Documents\\Github-Public\\PConv-Keras\\data\\logs\\50_weights_2018-06-01-16-41-43.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=10000,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,\n",
    "    epochs=50,        \n",
    "    plot_callback=plot_callback,\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir='../data/logs/initial_training', write_graph=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 - without batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "model = PConvUnet(weight_filepath='data/logs/')\n",
    "model.load(\n",
    "    r\"C:\\Users\\MAFG\\Documents\\Github-Public\\PConv-Keras\\data\\logs\\150_weights_2018-06-26-22-19-32.h5\",\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=10000,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,\n",
    "    epochs=20,        \n",
    "    workers=3,\n",
    "    plot_callback=plot_callback,\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir='../data/logs/fine_tuning', write_graph=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3 - Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "model = PConvUnet(weight_filepath='data/logs/')\n",
    "model.load(\n",
    "    r\"C:\\Users\\MAFG\\Documents\\Github-Public\\PConv-Keras\\data\\logs\\170_weights_2018-06-28-15-00-38.h5\",\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:28,  1.14s/it]"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for (masked, mask), ori in tqdm(test_generator):\n",
    "    \n",
    "    # Run predictions for this batch of images\n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    \n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[0].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[0].yaxis.set_major_formatter(NullFormatter())\n",
    "        axes[1].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[1].yaxis.set_major_formatter(NullFormatter())\n",
    "                \n",
    "        plt.savefig(r'data/test_samples/img_{}_{}.png'.format(i, pred_time))\n",
    "        plt.close()\n",
    "        n += 1\n",
    "        \n",
    "    # Only create predictions for about 100 images\n",
    "    if n > 100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
